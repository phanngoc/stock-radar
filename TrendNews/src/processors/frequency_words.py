"""
Frequency words processor for TrendRadar.

Handles loading and matching frequency word configurations.
"""

import os
from pathlib import Path
from typing import Dict, List, Tuple


def load_frequency_words(
    frequency_file: str = None,
) -> Tuple[List[Dict], List[str]]:
    """
    Load frequency words configuration.
    
    Args:
        frequency_file: Path to frequency words file
        
    Returns:
        Tuple of (processed_groups, filter_words)
        
    Raises:
        FileNotFoundError: If frequency words file doesn't exist
    """
    if frequency_file is None:
        frequency_file = os.environ.get(
            "FREQUENCY_WORDS_PATH", "config/frequency_words.txt"
        )

    frequency_path = Path(frequency_file)
    if not frequency_path.exists():
        raise FileNotFoundError(f"từ tần suấtfile {frequency_file} không tồn tại")

    with open(frequency_path, "r", encoding="utf-8") as f:
        content = f.read()

    word_groups = [group.strip() for group in content.split("\n\n") if group.strip()]

    processed_groups = []
    filter_words = []

    for group in word_groups:
        words = [word.strip() for word in group.split("\n") if word.strip()]

        group_required_words = []
        group_normal_words = []
        group_filter_words = []

        for word in words:
            if word.startswith("!"):
                filter_words.append(word[1:])
                group_filter_words.append(word[1:])
            elif word.startswith("+"):
                group_required_words.append(word[1:])
            else:
                group_normal_words.append(word)

        if group_required_words or group_normal_words:
            if group_normal_words:
                group_key = " ".join(group_normal_words)
            else:
                group_key = " ".join(group_required_words)

            processed_groups.append(
                {
                    "required": group_required_words,
                    "normal": group_normal_words,
                    "group_key": group_key,
                }
            )

    return processed_groups, filter_words



